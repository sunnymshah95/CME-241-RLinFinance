## Preface {.unnumbered}

We (Ashwin and Tikhon) have spent all of our educational and professional lives operating in the intersection of Mathematics and Computer Science - Ashwin for more than 3 decades and Tikhon for more than a decade. During these periods, we’ve commonly held two obsessions. The first is to bring together the (strangely) disparate worlds of Mathematics and Computer Science. The second is to focus on the pedagogy of various topics across Mathematics and Computer Science. Fundamentally, this book was born out of a deep desire to release our twin obsessions so as to not just educate the next generation of scientists and engineers, but to also present some new and creative ways of teaching technically challenging topics in ways that are easy to absorb and retain.

Apart from these common obsessions, each of us has developed significant expertise in a few topics that come together in this book. Ashwin’s undergraduate and doctoral education was in Computer Science, with specializations in Algorithms, Discrete Mathematics and Abstract Algebra. He then spent more than two decades of his career (across the Finance and Retail industries) in the realm of Computational Mathematics, recently focused on Machine Learning and Optimization. In his role as an Adjunct Professor at Stanford University, Ashwin specializes in Reinforcement Learning and Mathematical Finance. The content of this book is essentially an expansion of the content of the course CME 241 he teaches at Stanford. Tikhon’s education is in Computer Science and he has specialized in Software Design, with an emphasis on treating software design as mathematical specification of “what to do” versus computational mechanics of “how to do”. This is a powerful way to developing software, particularly for mathematical applications, significantly improving readability, modularity and correctness. This leads to code that naturally and clearly reflects the mathematics, thus blurring the artificial lines between Mathematics and Programming. He has also championed the philosophy of leveraging  programming as a powerful way to learn mathematical concepts. Ashwin has been greatly influenced by Tikhon on this philosophy and both of us have been quite successful in imparting our students with deep understanding of a variety of mathematical topics by using programming as a powerful pedagogical tool.

In fact, the key distinguishing feature of this book is to promote learning through an appropriate blend of A) intuitive understanding of the concepts, B) mathematical rigor, and C) programming of the models and algorithms (with sound software design principles that reflect the mathematical specification). We’ve found this unique approach to teaching facilitates strong retention of the concepts because students are *active learners* when they code everything they are learning, in a manner that reflects the mathematical concepts. We have strived to create a healthy balance between content accessibility and intuition development on one hand versus technical rigor and completeness on the other hand. Throughout the book, we provide proper mathematical notation, theorems (and sometimes formal proofs) as well as well-designed working code for various models and algorithms. But we have always accompanied this formalism with intuition development using simple examples and appropriate visualization.

We want to highlight that this book emphasizes the *foundational components* of Reinforcement Learning - Markov Decision Processes, Bellman Equations, Fixed-Points, Dynamic Programming, Function Approximation, Sampling, Experience-Replay, Batch Methods, Value-based versus Policy-based Learning, balancing Exploration and Exploitation, blending Planning and Learning etc. So although we have covered several key algorithms in this book, we do not dwell on specifics of the algorithms - rather, we emphasize the core principles and always allow for various types of flexibility in tweaking those algorithms (our investment in modular software design of the algorithms facilitates this flexibility). Likewise, we have kept the content of the financial applications fairly basic, emphasizing the core ideas, and developing working code for simplified versions of these financial applications. Getting these financial applications to be effective in practice is a much more ambitious endeavor - we don't attempt that in this book, but we highlight what it would take to make it work in practice. The theme of this book is understanding of core concepts rather than addressing all the nuances (and frictions) one typically encounters in the real-world. The financial content in this book is a significant fraction of the broader topic of Mathematical Finance and we hope that this book provides the side benefit of a fairly quick yet robust education in the key topics of Portfolio Management, Derivatives Pricing and Order-Book Trading.

We were introduced to modern Reinforcement Learning by the works of Richard Sutton, including his seminal book with Andrew Barto. There are several other works by other authors, many with more mathematical detail, but we found Sutton's works much easier to learn this topic. Our book tends to follow Sutton's less rigorous but more intuitive approach but we provide a bit more mathematical formalism/detail and we use precise working code instead of the typical psuedo-code found in textbooks on these topics. We have also been greatly influenced by David Silver's excellent  RL lectures series at University College London that is available on youtube. We have strived to follow the structure of David Silver's lecture series, typically augmenting it with more detail. So it pays to emphasize that the content of this book is not our original work. Rather, our contribution is to present content that is widely and publicly available in a manner that is easier to learn (particularly due to our augmented approach of "learning by coding"). Likewise, the financial content is not our original work - it is based on standard material on Mathematical Finance and based on a few papers that treat the Financial problems as Stochastic Control problems. However, we found the presentation in these papers not easy to understand for the typical student. Moreover, some of these papers did not explicitly model these problems as Markov Decision Processes, and some of them did not consider Reinforcement Learning as an option to solve these problems. So we presented the content in these papers in more detail, specifically with clearer notation and explanations, and with working Python code. It's interesting to note that Ashwin worked on some of these finance problems during his time at Goldman Sachs and Morgan Stanley, but at that time, these problems were not viewed from the lens of Stochastic Control. While designing the content of CME 241 at Stanford, Ashwin realized that several problems from his past finance career can be cast as Markov Decision Processes, which led him to the above-mentioned papers, which in turn led to the content creation for CME 241, that then extended into the financial content in this book. There are several Appendices in this book to succinctly provide appropriate pre-requisite mathematical/financial content. We have strived to provide references throughout the chapters and appendices to enable curious students to learn each topic in more depth. However, we are not exhaustive in our list of references because typically each of our references tends to be fairly exhaustive in the papers/books it in turn references.

We have many people to thank - those who provided the support and encouragement for us to write this book. Firstly, we would like to thank our managers at Target Corporation - Paritosh Desai and Mike McNamara. Ashwin would like to thank all of the faculty and staff at Stanford University he works with, for providing a wonderful environment and excellent support for CME 241, notably George Papanicolau, Kay Giesecke, Peter Glynn, Gianluca Iaccarino, Indira Choudhury and Jess Galvez. Ashwin would also like to thank all his students who implicitly proof-read the contents, and his course assistants Sven Lerner and Jeff Gu. Tikhon would like to thank XYZ.
